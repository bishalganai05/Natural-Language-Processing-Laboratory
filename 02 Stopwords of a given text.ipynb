{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import nltk"],"metadata":{"id":"2K7MIP-Ig0CA","executionInfo":{"status":"ok","timestamp":1701268655129,"user_tz":-330,"elapsed":5,"user":{"displayName":"Bishal Ganai","userId":"14338647434661618710"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hngwQrppg5PE","executionInfo":{"status":"ok","timestamp":1701268668408,"user_tz":-330,"elapsed":700,"user":{"displayName":"Bishal Ganai","userId":"14338647434661618710"}},"outputId":"7c42569c-4c89-4631-c7b8-08e6571eecc9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oqC7l46OWnIF","outputId":"c31510fa-6a02-434e-939d-c7f010242544","executionInfo":{"status":"ok","timestamp":1701268675640,"user_tz":-330,"elapsed":422,"user":{"displayName":"Bishal Ganai","userId":"14338647434661618710"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["['Good']\n","['we', 'will']\n","['Good', 'morning']\n","['we', 'will']\n","['Good', 'morning', 'everyone']\n","['we', 'will']\n","['Good', 'morning', 'everyone', '.']\n","['we', 'will']\n","['Good', 'morning', 'everyone', '.', 'Today']\n","['we', 'will']\n","['Good', 'morning', 'everyone', '.', 'Today', 'study']\n","['we', 'will']\n","['Good', 'morning', 'everyone', '.', 'Today', 'study', 'NLTK']\n","['we', 'will']\n","['Good', 'morning', 'everyone', '.', 'Today', 'study', 'NLTK', '.']\n","['we', 'will']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import nltk.corpus\n","\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","nltk.download(\"stopwords\")\n","stop_words=set(stopwords.words(\"english\"))\n","text = \"Good morning everyone. Today we will study NLTK.\"\n","words=word_tokenize(text)\n","remove_stopwords=[]\n","for i in words:\n","   if i not in stop_words:\n","     remove_stopwords.append(i)\n","     print (remove_stopwords)\n","     remove_words=[]\n","     remove_words=[i for i in words if i in stop_words]\n","     print (remove_words)\n"]}]}